---
title: "MLassignment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

## 1. Synopsis

**Problem**: The objective of this assignment is to analyze data from from accelerometers on the belt, forearm, arm, and dumbell of 6 participants who were asked to perform barbell lifts correctly and incorrectly in 5 different ways. Participants performed the exercises: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). The goal of the project was to predict the manner in which they did the exercise based on collected body sensor data.

More information about the data set is available from the website here: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

Training data: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
Test data: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

**Result**: Using a random forest model on a final set of 54 variables, the classifier achieved a prediction accuracy of 99.2%.


## 2. Set environment.

```{r loadlibraries, echo=TRUE}
remove(list=ls())
set.seed(83749)

library(ggplot2)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
```

## 3. Data processing.

Load data then remove variables with excess NA values or near zero values.

```{r readdata,cache=TRUE}
data_train <- read.csv("pml-training.csv")
data_valid <- read.csv("pml-testing.csv")

#remove near zero variables (reduces to 100 variables)
nzv <- nearZeroVar(data_train)
data_train <- data_train[,-nzv]
data_valid <- data_valid[,-nzv]
dim(data_train)
dim(data_valid)

#remove NA-variables (reduces to 59 variables)
navars <- sapply(data_train, function(x) mean(is.na(x))) > 0.95
data_train <- data_train[,navars==FALSE]
data_valid <- data_valid[,navars==FALSE]
dim(data_train)
dim(data_valid)

#finally adjust output variables and remove label columns (reduces to 53)
data_train$classe <- factor(data_train$classe)
data_train <- data_train[,7:59]
data_valid <- data_valid[,7:59]
dim(data_train)
dim(data_valid)
```

## 4. Prediction Model
Implementing random forest model since this is a well behaving algorithm for a braod range of multi-class data.

```{r model set up, cache=TRUE}
#partition training data in training and testing set, so that we can arrive at a fair assessment
inTrain  <- createDataPartition(data_train$classe, p=0.6, list=FALSE)
trainset <- data_train[inTrain,]
testset <- data_train[-inTrain,]
dim(trainset)
dim(testset)

#train model
trControl = trainControl(method = "cv", number = 3, verboseIter = TRUE, allowParallel = TRUE)
modFit <- train(classe ~ ., data = trainset, method = "rf", trControl = trControl)
print(modFit, digits=3)

```

The final model suggests greatest importance from the **roll_belt** and **pitch_frearm** variables, followed by **yaw_belt**.

```{r variable plot, cache=TRUE}
#plot variable importance
varimp <- varImp(modFit)
plot(varimp, main = "Importance of Top 15 Variables", top = 15)

```

Model performance on test data was **99%**.

```{r model testing, cache=TRUE}
#test on reserved test set
pred <- predict(modFit, newdata=testset)
confMat <- confusionMatrix(pred, testset$classe)
print(confMat, digits=3)
```

## Validation set

The final predictions on the validation cases were correctly identified.

```{r model validation, cache=TRUE}
finalPred <- predict(modFit, newdata = data_valid)
finalPred
```

## Reference

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. **Qualitative Activity Recognition of Weight Lifting Exercises.** *Proceedings of 4th International Conference in Cooperation with SIGCHI* (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. 

